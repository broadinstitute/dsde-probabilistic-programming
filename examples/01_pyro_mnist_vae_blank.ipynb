{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised MNIST: part 1\n",
    "\n",
    "### Linear variational autoencoder\n",
    "\n",
    "##### a Pyro demo\n",
    "\n",
    "Stephen Fleming, 20190204\n",
    "\n",
    "for reference, see http://pyro.ai/examples/vae.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The generative model__\n",
    "\n",
    "For a latent variable $z \\in \\mathbb{R}^q$, and observed data $x \\in \\mathbb{R}^d$ with $q < d$, and a scalar $\\sigma$,\n",
    "\n",
    "$$ z \\sim \\mathcal{N} (\\mathbb{0}, \\mathbb{1}) $$\n",
    "$$ x | z \\sim \\mathcal{N} (W z + b, \\sigma^2 \\mathbb{1}) $$\n",
    "\n",
    "Here $W$ is an arbitrary $d \\times q$ matrix, and $b$ is a $d$-dimensional vector.  This sort of linear transformation ($W z + b$) can be parameterized using a PyTorch module called nn.Linear(), to make life easy.\n",
    "\n",
    "Note that this model is not perfect... especially since the data have pixel intensities $\\in \\{0, 1 \\}$.  You will see that the Pyro example on the website uses a Bernoulli distribution instead, and that their image reconstructions are binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](vae_model.png \"Graphical model for a variational autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The variational posterior__\n",
    "\n",
    "Given $x_i$, we would like a way to come up with $z_i$.  We could either memorize a new $z_i$ for each datapoint $i$, or we can _amortize_ our inference procedure by learning a mapping from $x$ to $z$.  We will do the latter.  Call that function $f(x)$.  Then our variational posterior for $p(z|x)$ is as follows:\n",
    "\n",
    "$$ z_\\mu, z_\\sigma = f(x) $$\n",
    "$$ z | x \\sim \\mathcal{N} (z_\\mu, z_\\sigma) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.optim import Adamax\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import constraints\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([512, 1, 28, 28])\n",
      "output shape: torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACECAYAAACnKFEWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBA0ZAALxX6Y2eHUFScV1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for loading and batching MNIST dataset\n",
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = datasets.MNIST(root=root, train=True, transform=trans,\n",
    "                               download=download)\n",
    "    test_set = datasets.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "#     kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    kwargs = {'num_workers': 0, 'pin_memory': False}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=512, use_cuda=USE_CUDA)\n",
    "\n",
    "# check out data loading to see what we get\n",
    "\n",
    "for data in train_loader:\n",
    "    print(f'input shape: {data[0].shape}')\n",
    "    print(f'output shape: {data[1].shape}')\n",
    "    plt.figure()\n",
    "    for i in range(min(3, data[1].shape[0])):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(data[0][i, ...].numpy().squeeze(), cmap='gray')\n",
    "        plt.title(data[1][i].item())\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the encoder and decoder: use nn.Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Pyro model and guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class VAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up the model\n",
    "\n",
    "Q = 100  # dimensionality of our latent embedding\n",
    "\n",
    "D = 28*28\n",
    "assert Q < D, \"The embedded dimension must be less than that of the data.\"\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "encoder = Encoder(D, Q)\n",
    "decoder = Decoder(Q, D)\n",
    "\n",
    "vae = VAE(encoder, decoder, use_cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up inference\n",
    "\n",
    "optimizer = Adamax({\"lr\": 1.0e-3})\n",
    "\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# running inference\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "TEST_FREQUENCY = 5\n",
    "\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=512, use_cuda=USE_CUDA)\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the progress of training\n",
    "\n",
    "plt.plot(np.arange(0, len(train_elbo)), np.array(train_elbo))\n",
    "plt.plot(np.arange(0, len(train_elbo), TEST_FREQUENCY), np.array(test_elbo), '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('Training procedure')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the latent embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine the embedding...\n",
    "\n",
    "# compute the embedding\n",
    "\n",
    "z = np.empty([1, Q])\n",
    "labels = np.empty(1)\n",
    "\n",
    "for data in test_loader:\n",
    "    if z.shape[0] >= 3000:\n",
    "        break\n",
    "    z = np.concatenate((z, vae.encoder(data[0].to(device=vae.device)\n",
    "                                       .view(data[0].shape[0], -1))['loc']\n",
    "                        .detach().cpu().numpy()))\n",
    "    labels = np.concatenate((labels, data[1].numpy()))\n",
    "\n",
    "z[np.isnan(z)] = 0\n",
    "z[z > 1e100] = 1e100\n",
    "    \n",
    "# plot it\n",
    "\n",
    "# and I know this sounds ridiculous but we have to do more\n",
    "# dimensionality reduction to visualize our dimensionality reduction\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "z_tsne = TSNE(n_components=2).fit_transform(z)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "plt.figure(figsize=(8, 8), frameon=False)\n",
    "for k in np.unique(labels):\n",
    "    plt.plot(z_tsne[labels==k, 0], \n",
    "             z_tsne[labels==k, 1], '.', ms=8, alpha=0.5)\n",
    "\n",
    "lgnd = plt.legend(np.unique(labels).astype(int), \n",
    "                  loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for i in range(len(lgnd.legendHandles)):\n",
    "    lgnd.legendHandles[i]._legmarker.set_markersize(20)\n",
    "    lgnd.legendHandles[i]._legmarker.set_alpha(1)\n",
    "\n",
    "plt.xlabel('TSNE 0')\n",
    "plt.ylabel('TSNE 1')\n",
    "plt.title('Visualization of embedding')\n",
    "plt.box(on=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image reconstruction\n",
    "\n",
    "for d in range(data[0].shape[0]):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(data[0][d, ...].numpy().squeeze(), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Original')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    embedding = vae.encoder(data[0][d, ...].to(device=vae.device).view(1, -1))['loc']\n",
    "    reconstruction = vae.decoder(embedding).detach().cpu().view((28, 28)).numpy()\n",
    "\n",
    "    plt.imshow(reconstruction, cmap='gray',\n",
    "               vmin=0, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Reconstruction')\n",
    "    plt.show()\n",
    "    if d > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw me some numbers (this uses label information)\n",
    "# interpolate between two digits\n",
    "\n",
    "num1 = 3\n",
    "num2 = 8\n",
    "\n",
    "z1_mean = z[labels==num1].mean(axis=0)  # a sort of 'average digit' in latent space\n",
    "z2_mean = z[labels==num2].mean(axis=0)\n",
    "\n",
    "# for i in z1_mean.size:\n",
    "z_interp = np.concatenate([np.expand_dims(np.linspace(z1_mean[i], z2_mean[i], 5), 0)\n",
    "                           for i in range(z1_mean.size)]).transpose()\n",
    "z_interp = torch.Tensor(z_interp).to(device=vae.device)\n",
    "\n",
    "for i in range(z_interp.shape[0]):\n",
    "    reconstruction = vae.decoder(z_interp[i, ...]).detach().cpu().view((28, 28)).numpy()\n",
    "    \n",
    "    plt.imshow(reconstruction, cmap='gray',\n",
    "               vmin=0, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
